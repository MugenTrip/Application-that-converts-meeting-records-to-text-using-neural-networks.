Use 
<addr> `git lfs clone` 
to download the full repository with the pretrained models <br />
If you download the zip file you will need to download separately 2 ".cpkt" models from <br />  "pretrained_models/speech_separation/exp/train_chimera_my_tag" and "pretrained_models/speech_separation/exp_16/train_chimera_my_tag" and place them in same local directory. <br /> <br /> 

Make sure you have install node, python at least 3.7 and pip <br />
Then you will need to install torch, [asteroid], [speechbrain] and [pyannote]. <br />
Run `npm install` to install the necessary node_modules <br />
  
A complete setup guide will be uploaded soon <br />
  
## References
[1] H. Bredin et al., “pyannote.audio: neural building blocks for speaker diarization,” Barcelona,
Spain, May 2020. <br />
[2] M. Ravanelli et al., SpeechBrain. GitHub, 2021 <br />
[3] M. Pariente et al., “Asteroid: the PyTorch-based audio source separation toolkit for researchers,” 2020.


  

  [asteroid]: https://github.com/asteroid-team/asteroid
  [speechbrain]: https://github.com/speechbrain/speechbrain
  [pyannote]: https://github.com/pyannote/pyannote-audio
